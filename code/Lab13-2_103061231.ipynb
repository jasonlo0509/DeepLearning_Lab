{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "1. Read lines from file and remove non-alphanumeric tokens(except space and apostrophe to keep the format)\n",
    "2. Create vocabulary list from the lines\n",
    "3. Put BEG, END, PAD, UNK into voc-index mapping list.\n",
    "4. Create mapping lists between vocabularies and indices while dropping rare vacabularies.\n",
    "5. Encode lines to indices lists also add BEG and END.\n",
    "6. Drop the lines with UNK words.\n",
    "7. Form dialog sets from lines in proper length.\n",
    "8. Find max length which is most likely the threshold we set in 7th step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch preparation\n",
    "Create encoder's input, decoder's input and output based on dialog sets above.\n",
    "Perform padding by adding PAD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Train the seq2seq model with 40 epochs and record the loss at each epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cherry pick\n",
    "Randomly pick inputs and predict their outputs.  We sort the results based on similarity(BLEU score) and print out top predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lines = []\n",
    "file = open('./dataset/chatbot/conversations.txt', 'r')\n",
    "for line in file:\n",
    "     lines.append(line)\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "allowed_ch = []\n",
    "allowed_ch.append(chr(39)) #'\n",
    "allowed_ch.append(chr(32)) #space\n",
    "for i in range(97,97+26):\n",
    "    allowed_ch.append(chr(i))\n",
    "\n",
    "print(allowed_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again', \" well i thought we'd start with pronunciation if that's okay with you\", ' not the hacking and gagging and spitting part please', \" okay then how 'bout we try out some french cuisine saturday night\", '', \" you're asking me out that's so cute what's your name again\", ' forget it', '', \" no no it's my fault  we didn't have a proper introduction \", ' cameron']\n"
     ]
    }
   ],
   "source": [
    "dat = []\n",
    "for line in lines:\n",
    "    new_l =''\n",
    "    for w in line.split():\n",
    "        s = ''.join([letter for letter in w if letter in allowed_ch])\n",
    "        new_l += ' ' + s\n",
    "    dat.append(new_l)\n",
    "\n",
    "print(dat[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "\n",
    "def add_vocab(w):\n",
    "    if(len(w)) < 1:\n",
    "        return\n",
    "    if not w in vocab:\n",
    "        vocab[w] = 1\n",
    "    else:\n",
    "        vocab[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in dat:\n",
    "    for w in line.split():\n",
    "        add_vocab(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thrhd = 60\n",
    "count = 0\n",
    "for k,v in vocab.items():\n",
    "    if v >= thrhd:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of total vocab: 67977\n",
      "Size of vocab we will use: 2970\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of total vocab:\", len(vocab))\n",
    "print(\"Size of vocab we will use:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "def build_voc_mapping(voc_cnt, thrhd):\n",
    "  \"\"\"\n",
    "    enc_map: voc --encode--> id\n",
    "    dec_map: id --decode--> voc\n",
    "    \"\"\"\n",
    "\n",
    "  def add(enc_map, dec_map, voc):\n",
    "    enc_map[voc] = len(dec_map)\n",
    "    dec_map[len(dec_map)] = voc\n",
    "    return enc_map, dec_map\n",
    "\n",
    "  # add <ST>, <ED>, <RARE>\n",
    "  enc_map, dec_map = {}, {}\n",
    "  for voc in ['<BEG>', '<END>', '<UNK>', '<PAD>']:\n",
    "    enc_map, dec_map = add(enc_map, dec_map, voc)\n",
    "  for voc, cnt in voc_cnt.items():\n",
    "    if int(cnt) < thrhd:  # rare words => <RARE>\n",
    "      enc_map[voc] = enc_map['<UNK>']\n",
    "    else:\n",
    "      enc_map, dec_map = add(enc_map, dec_map, voc)\n",
    "  return enc_map, dec_map\n",
    "\n",
    "\n",
    "enc_map, dec_map = build_voc_mapping(vocab, thrhd)\n",
    "# save enc/decoding map to disk\n",
    "cPickle.dump(enc_map, open('./enc_map.pkl', 'wb'))\n",
    "cPickle.dump(dec_map, open('./dec_map.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lines_to_ids(enc_map, dat):\n",
    "  lines_ids = []\n",
    "  for line in dat:   \n",
    "    icap = [enc_map[x] for x in line.split()]\n",
    "    icap.insert(0, enc_map['<BEG>'])\n",
    "    icap.append(enc_map['<END>'])\n",
    "    lines_ids.append(icap)\n",
    "  return lines_ids\n",
    "\n",
    "\n",
    "enc_map = cPickle.load(open('./enc_map.pkl', 'rb'))\n",
    "\n",
    "dat_proc = lines_to_ids(enc_map, dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_clean = []\n",
    "\n",
    "for i in range(len(dat_proc)):\n",
    "  if not (enc_map['<UNK>'] in dat_proc[i]):  # remove '<UNK>' sentence\n",
    "    dat_clean.append(dat_proc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1439, 2356, 2855, 2542, 335, 2766, 519, 550, 1297, 1126, 154, 1], [0, 2344, 1588, 1], [0, 1], [0, 1592, 1742, 836, 1566, 1517, 2698, 2261, 612, 2767, 1], [0, 1], [0, 1543, 1], [0, 335, 2698, 1448, 1], [0, 1], [0, 1690, 2855, 2315, 1990, 1311, 1087, 1671, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(dat_clean[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data usage 63.27247879116062\n"
     ]
    }
   ],
   "source": [
    "print('data usage {}'.format(len(dat_clean)/len(dat)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1493077\n",
      "Number of times <UNK> is used: 0\n",
      "Percent of words that are <UNK>: 0.0%\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "for line in dat_clean:\n",
    "    for w in line:\n",
    "        if w == enc_map[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "        word_count += 1\n",
    "    \n",
    "unk_ratio = round(unk_count/word_count,4)*100\n",
    "    \n",
    "print(\"Total number of words:\", word_count)\n",
    "print(\"Number of times <UNK> is used:\", unk_count)\n",
    "print(\"Percent of words that are <UNK>: {}%\".format(round(unk_ratio,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs_corpus = []\n",
    "ys_corpus = []\n",
    "\n",
    "for i in range(len(dat_clean)-1):\n",
    "    xs = dat_clean[i]\n",
    "    ys = dat_clean[i+1]\n",
    "    if len(xs) > 20 or len(xs) < 3 or len(ys) > 20 or len(ys) < 3:\n",
    "        continue\n",
    "    xs_corpus.append(xs)\n",
    "    ys_corpus.append(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BEG> you're asking me out that's so cute what's your name again <END>\n",
      "<BEG> forget it <END>\n",
      "\n",
      "\n",
      "<BEG> why <END>\n",
      "<BEG> that's a shame <END>\n",
      "\n",
      "\n",
      "<BEG> that's because it's such a nice one <END>\n",
      "<BEG> forget french <END>\n",
      "\n",
      "\n",
      "<BEG> there <END>\n",
      "<BEG> where <END>\n",
      "\n",
      "\n",
      "<BEG> you have my word as a gentleman <END>\n",
      "<BEG> you're sweet <END>\n",
      "\n",
      "\n",
      "<BEG> sure have <END>\n",
      "<BEG> i really really really wanna go but i can't not unless my sister goes <END>\n",
      "\n",
      "\n",
      "<BEG> i really really really wanna go but i can't not unless my sister goes <END>\n",
      "<BEG> i'm workin' on it but she doesn't seem to be goin' for him <END>\n",
      "\n",
      "\n",
      "<BEG> she's not a <END>\n",
      "<BEG> so that's the kind of guy she likes pretty ones <END>\n",
      "\n",
      "\n",
      "<BEG> hi <END>\n",
      "<BEG> looks like things worked out tonight huh <END>\n",
      "\n",
      "\n",
      "<BEG> well no <END>\n",
      "<BEG> then that's all you had to say <END>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc_map = cPickle.load(open('./enc_map.pkl', 'rb'))  # token => id\n",
    "dec_map = cPickle.load(open('./dec_map.pkl', 'rb'))  # id => token\n",
    "vocab_size = len(dec_map)\n",
    "\n",
    "for i in range(10):\n",
    "    print(' '.join([dec_map[idx] for idx in xs_corpus[i]]))\n",
    "    print(' '.join([dec_map[idx] for idx in ys_corpus[i]]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n"
     ]
    }
   ],
   "source": [
    "xs_max_len = 0\n",
    "ys_max_len = 0\n",
    "\n",
    "for i in range(len(xs_corpus)):  # caculate max length\n",
    "  xs_max_len = max(xs_max_len, len(xs_corpus[i]))\n",
    "  ys_max_len = max(ys_max_len, len(ys_corpus[i]))\n",
    "\n",
    "print(xs_max_len, ys_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "\n",
    "  def __init__(self, xs_corpus, ys_corpus, xs_pad, ys_pad, xs_max_len, ys_max_len, batch_size):\n",
    "    n = len(xs_corpus)\n",
    "    batch_num = len(xs_corpus) // batch_size\n",
    "    n = batch_num * batch_size\n",
    "\n",
    "    self.xs = [np.zeros(n, dtype=np.int32)\n",
    "               for _ in range(xs_max_len)]  # encoder inputs\n",
    "    self.ys = [np.zeros(n, dtype=np.int32)\n",
    "               for _ in range(ys_max_len)]  # decoder inputs\n",
    "    self.gs = [np.zeros(n, dtype=np.int32)\n",
    "               for _ in range(ys_max_len)]  # decoder outputs\n",
    "    self.ws = [np.zeros(n, dtype=np.float32)\n",
    "               for _ in range(ys_max_len)]  # decoder weight for loss caculation\n",
    "\n",
    "    self.xs_max_len = xs_max_len\n",
    "    self.ys_max_len = ys_max_len\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    for b in range(batch_num):\n",
    "        for i in range(b * batch_size, (b + 1) * batch_size):\n",
    "            for j in range(len(xs_corpus[i]) - 2):\n",
    "                self.xs[j][i] = xs_corpus[i][j + 1]\n",
    "            for j in range(j + 1, xs_max_len):\n",
    "                self.xs[j][i] = xs_pad\n",
    "\n",
    "            for j in range(len(ys_corpus[i]) - 1):\n",
    "                self.ys[j][i] = ys_corpus[i][j]\n",
    "                self.gs[j][i] = ys_corpus[i][j + 1]\n",
    "                self.ws[j][i] = 1.0\n",
    "            for j in range(j + 1, ys_max_len):  # don't forget padding and let loss weight zero\n",
    "                self.ys[j][i] = ys_pad\n",
    "                self.gs[j][i] = ys_pad\n",
    "                self.ws[j][i] = 0.0\n",
    "\n",
    "  def get(self, batch_id):\n",
    "    x = [\n",
    "        self.xs[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.xs_max_len)\n",
    "    ]\n",
    "    y = [\n",
    "        self.ys[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.ys_max_len)\n",
    "    ]\n",
    "    g = [\n",
    "        self.gs[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.ys_max_len)\n",
    "    ]\n",
    "    w = [\n",
    "        self.ws[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.ys_max_len)\n",
    "    ]\n",
    "\n",
    "    return x, y, g, w\n",
    "\n",
    "\n",
    "batch = BatchGenerator(xs_corpus, ys_corpus, enc_map['<PAD>'],\n",
    "                       enc_map['<PAD>'], xs_max_len, ys_max_len, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BEG> looks like things worked out tonight huh <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "looks like things worked out tonight huh <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "well no <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BEG> then that's all you had to say <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "then that's all you had to say <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "then that's all you had to say <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BEG> but <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "but <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "do you listen to this crap <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BEG> what crap <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "what crap <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y, g, w = batch.get(2)\n",
    "for i in range(4):\n",
    "  print(' '.join([dec_map[x[j][i]] for j in range(xs_max_len)]))\n",
    "  print(' '.join([dec_map[y[j][i]] for j in range(ys_max_len)]))\n",
    "  print(' '.join([dec_map[g[j][i]] for j in range(ys_max_len)]))\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MachineTranslationSeq2Seq:\n",
    "\n",
    "  def __init__(self, xs_max_len, ys_max_len, xs_size, ys_size):\n",
    "    self.xs_max_len = xs_max_len\n",
    "    self.ys_max_len = ys_max_len\n",
    "\n",
    "    with tf.variable_scope('seq2seq_intput/output'):\n",
    "      self.enc_inputs = [\n",
    "          tf.placeholder(tf.int64, [None]) for i in range(xs_max_len)\n",
    "      ]  # time mojor feed\n",
    "      self.dec_inputs = [\n",
    "          tf.placeholder(tf.int64, [None]) for i in range(ys_max_len)\n",
    "      ]\n",
    "      self.groundtruths = [\n",
    "          tf.placeholder(tf.int64, [None]) for i in range(ys_max_len)\n",
    "      ]\n",
    "      self.weights = [\n",
    "          tf.placeholder(tf.float32, [None]) for i in range(ys_max_len)\n",
    "      ]\n",
    "\n",
    "    with tf.variable_scope('seq2seq_rnn'):  # training by teacher forcing\n",
    "      self.out_cell = tf.contrib.rnn.LSTMCell(512)\n",
    "      self.outputs, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "          self.enc_inputs, self.dec_inputs, self.out_cell, xs_size, ys_size,\n",
    "          300)\n",
    "    with tf.variable_scope(\n",
    "        'seq2seq_rnn', reuse=True):  # predict by feeding previous\n",
    "      self.pred_cell = tf.contrib.rnn.LSTMCell(\n",
    "          512, reuse=True)  # reuse cell for train and test\n",
    "      self.predictions, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "          self.enc_inputs,\n",
    "          self.dec_inputs,\n",
    "          self.pred_cell,\n",
    "          xs_size,\n",
    "          ys_size,\n",
    "          300,\n",
    "          feed_previous=True)\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "      # caculate weighted loss\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.contrib.legacy_seq2seq.sequence_loss_by_example(\n",
    "              self.outputs, self.groundtruths, self.weights))\n",
    "      self.optimizer = tf.train.AdamOptimizer(0.002).minimize(self.loss)\n",
    "\n",
    "    self.sess = tf.Session()\n",
    "    self.saver = tf.train.Saver()\n",
    "    self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  def train(self, x, y, g, w):\n",
    "    fd = {}\n",
    "    for i in range(self.xs_max_len):\n",
    "      fd[self.enc_inputs[i]] = x[i]  # show how to feed a list\n",
    "\n",
    "    for i in range(self.ys_max_len):\n",
    "      fd[self.dec_inputs[i]] = y[i]\n",
    "      fd[self.groundtruths[i]] = g[i]\n",
    "      fd[self.weights[i]] = w[i]\n",
    "\n",
    "    loss, _ = self.sess.run([self.loss, self.optimizer], fd)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def output(self, x, y):\n",
    "    fd = {}\n",
    "    for i in range(self.xs_max_len):\n",
    "      fd[self.enc_inputs[i]] = x[i]\n",
    "\n",
    "    for i in range(self.ys_max_len):\n",
    "      fd[self.dec_inputs[i]] = y[i]\n",
    "\n",
    "    out = self.sess.run(self.outputs, fd)\n",
    "\n",
    "    return out\n",
    "\n",
    "  def predict(self, x, ys_beg):\n",
    "    fd = {}\n",
    "    for i in range(self.xs_max_len):\n",
    "      fd[self.enc_inputs[i]] = x[i]\n",
    "\n",
    "    for i in range(self.ys_max_len):  \n",
    "    # when feed previous, the fist token should be '<BEG>', and others are useless\n",
    "      if i == 0:\n",
    "        fd[self.dec_inputs[i]] = np.ones(y[i].shape, dtype=np.int32) * ys_beg\n",
    "      else:\n",
    "        fd[self.dec_inputs[i]] = np.zeros(y[i].shape, dtype=np.int32)\n",
    "\n",
    "    pd = self.sess.run(self.predictions, fd)\n",
    "\n",
    "    return pd\n",
    "\n",
    "  def save(self, e):\n",
    "    self.saver.save(self.sess, 'model/seq2seq/seq2seq_%d.ckpt' % (e + 1))\n",
    "\n",
    "  def restore(self, e):\n",
    "    self.saver.restore(self.sess, 'model/seq2seq/seq2seq_%d.ckpt' % (e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = MachineTranslationSeq2Seq(xs_max_len, ys_max_len,\n",
    "                                  len(enc_map), len(dec_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 200\n",
    "batch_num = len(xs_corpus) // BATCH_SIZE\n",
    "\n",
    "batch = BatchGenerator(xs_corpus, ys_corpus, enc_map['<PAD>'],\n",
    "                       enc_map['<PAD>'], xs_max_len, ys_max_len, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:0, LOSS:4.46940435315961\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:1, LOSS:3.913471751123945\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:2, LOSS:3.6703528951261646\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:3, LOSS:3.4097770196255124\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:4, LOSS:3.1376057562426984\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:5, LOSS:2.889105284882483\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:6, LOSS:2.6738659550096386\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:7, LOSS:2.4904117397615844\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:8, LOSS:2.3319309888599076\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:9, LOSS:2.193650005019714\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:10, LOSS:2.0740541729414574\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:11, LOSS:1.9781859063099478\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:12, LOSS:1.8896161081077896\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:13, LOSS:1.8120386260692205\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:14, LOSS:1.744707724201345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:15, LOSS:1.6795706347884418\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:16, LOSS:1.622174625084779\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:17, LOSS:1.5713691129305651\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:18, LOSS:1.5339131901197345\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:19, LOSS:1.4918358928967859\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:20, LOSS:1.4542844881799732\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:21, LOSS:1.4226166270325118\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:22, LOSS:1.3955052474113268\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:23, LOSS:1.3704859821874404\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:24, LOSS:1.3310299891734791\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:25, LOSS:1.3066711301837013\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:26, LOSS:1.290589179530322\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:27, LOSS:1.2739230051775958\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:28, LOSS:1.2534350545328354\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:29, LOSS:1.2325254744179894\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:30, LOSS:1.2113693758984592\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:31, LOSS:1.2055845681194948\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:32, LOSS:1.1979476741262685\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:33, LOSS:1.180512216185855\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:34, LOSS:1.165515333692604\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:35, LOSS:1.157504661617992\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:36, LOSS:1.1447116440144656\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:37, LOSS:1.1286067803886448\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:38, LOSS:1.116253896990669\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "EPOCH:39, LOSS:1.0931843385518154\n"
     ]
    }
   ],
   "source": [
    "rec_loss = []\n",
    "for e in range(EPOCHS):\n",
    "  train_loss = 0\n",
    "\n",
    "  for b in range(batch_num):\n",
    "    if b % 100 ==0: print(b)\n",
    "    x, y, g, w = batch.get(b)\n",
    "    batch_loss = model.train(x, \n",
    "                             y, g, w)\n",
    "    train_loss += batch_loss\n",
    "\n",
    "  train_loss /= batch_num\n",
    "  print('EPOCH:{}, LOSS:{}'.format(e,train_loss))\n",
    "  rec_loss.append(train_loss)\n",
    "  model.save(e)\n",
    "\n",
    "np.save('./model/seq2seq/rec_loss.npy', rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBKX/D6deNP5Ev1cVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97fa801da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rec_loss = np.load('./model/seq2seq/rec_loss.npy')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_loss = plt.plot([rec_loss[i] for i in range(len(rec_loss))])\n",
    "plt.legend(['Loss'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('./LOSS.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/seq2seq/seq2seq_40.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.restore(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def cherry_pick(records, n, upper_bound=1.0):\n",
    "  bleus = []\n",
    "\n",
    "  for xs, ys_gr, ys_pd in records:\n",
    "    bleu = nltk.translate.bleu_score.sentence_bleu(\n",
    "        [ys_gr], ys_pd)  # caculate BLEU by nltk\n",
    "    bleus.append(bleu)\n",
    "\n",
    "  lst = [i for i in range(len(records)) if bleus[i] <= upper_bound]\n",
    "  lst = sorted(lst, key=lambda i: bleus[i], reverse=True)  # sort by BLEU score\n",
    "\n",
    "  return [records[lst[i]] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing okay some of us have been a little not concerned exactly but\n",
      "tell me\n",
      "tell me\n",
      "\n",
      "what do you suggest\n",
      "that you come with me\n",
      "that you come with me\n",
      "\n",
      "it was my father's kept it in his wallet he was murdered\n",
      "you sound so sure\n",
      "you sound so sure\n",
      "\n",
      "i guess i might as well get this done with\n",
      "what should i do\n",
      "what should i do\n",
      "\n",
      "is that the kind of girl you think i am what can i do to make you relax\n",
      "you could give me the gun\n",
      "you could give me the gun\n",
      "\n",
      "i'm her husband\n",
      "husband\n",
      "husband\n",
      "\n",
      "at least i'll have company when i die ain't that right jake\n",
      "for christ's sake john throw me the keys\n",
      "for christ's sake john throw me the keys\n",
      "\n",
      "now what's this\n",
      "give it to me\n",
      "give it to me\n",
      "\n",
      "okay fine\n",
      "fine fine what\n",
      "fine fine what\n",
      "\n",
      "oh this and that\n",
      "what i've been doing\n",
      "what i've been doing\n",
      "\n",
      "well it's a living but i'm excited about this\n",
      "what is it a still life\n",
      "what is it a still life\n",
      "\n",
      "can we have it by tonight\n",
      "well if it's absolutely necessary\n",
      "well if it's absolutely necessary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/home/chen/anaconda3/envs/tensorflow/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "records = []\n",
    "\n",
    "for i in range(10):\n",
    "  i = rd.randint(0, batch_num - 1)  # random pick one to translate\n",
    "\n",
    "  x, y, g, w = batch.get(i)\n",
    "  out = model.output(x, y)\n",
    "  pd = model.predict(x, enc_map['<BEG>'])\n",
    "\n",
    "  for j in range(10):\n",
    "    j = rd.randint(0, BATCH_SIZE - 1)\n",
    "\n",
    "    xs = [dec_map[x[i][j]] for i in range(xs_max_len)]\n",
    "    xs = xs[:xs.index('<PAD>')]\n",
    "    ys_gr = [dec_map[g[i][j]] for i in range(ys_max_len)]\n",
    "    if '<END>' in ys_gr:\n",
    "      ys_gr = ys_gr[:ys_gr.index('<END>')]\n",
    "    ys_pd = [dec_map[np.argmax(pd[i][j, :])] for i in range(ys_max_len)]\n",
    "    if '<END>' in ys_pd:\n",
    "      ys_pd = ys_pd[:ys_pd.index('<END>')]\n",
    "\n",
    "    records.append([xs, ys_gr, ys_pd])\n",
    "\n",
    "n = 12  # how many result we show\n",
    "rec_cherry = cherry_pick(records, n)\n",
    "\n",
    "for i in range(n):\n",
    "  for j in range(3):\n",
    "    print(' '.join(rec_cherry[i][j]))\n",
    "\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -sf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
